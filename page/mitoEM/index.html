<html xmlns="http://www.w3.org/1999/xhtml">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>MitoEM Dataset: Large-scale 3D Mitochondria Instance Segmentation from EM Images</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="We seek to understand the arrow of time in videos--what makes videos look like playing forwards or backwards?  Can we visualize the cues? Can the arrow of time be a supervisory signal useful for activity analysis? To this end, we apply a learning-based approach to a large set of videos. To learn the arrow of time efficiently and reliably, we design a ConvNet suitable for extended temporal footprints and for the class activation visualization, and study the effect of artificial cues, such as inematographic conventions, on learning. Our trained model achieves the state-of-the-art performance on two large-scale real-world video datasets.  Through cluster analysis, we examine the learned visual cues, showing when and where they occur. Lastly, we use the trained ConvNet for two applications: self-supervision for action recognition, and video forensics -- determining whether Hollywood film clips have been deliberately reversed in time as special effects.">
<meta name="keywords" content="arrow of time; unsupervised learning; deep learning;">

<!-- Fonts and stuff -->
<link href="./src/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./src/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./src/iconize.css">
<script async="" src="./src/prettify.js"></script>
<style>
.highlight {
  padding: 1.5rem;
  margin-right: 0;
  margin-left: 0;  
}

</style>

</head>

<body>
  <div id="content">
    <div id="content-inner">
      <div class="section head">
	<h1>MitoEM Dataset: Large-scale 3D Mitochondria Instance Segmentation from EM Images</h1>
    <br/>
	<div class="authors">
	  <a href="https://people.csail.mit.edu/donglai/">Donglai Wei</a><sup>1</sup>&nbsp;
      <a href="https://zudi-lin.github.io/projects/">Zudi Lin<sup>1</sup>&nbsp;	  
	  Daniel Franco-Barranco<sup>2,3</sup>&nbsp;
	  Nils Wendt<sup>4*</sup>&nbsp;
	  Xingyu Liu<sup>5*</sup>&nbsp;
	  Wenjie Yin<sup>1*</sup>&nbsp; 
	  Xin Huang<sup>6*</sup>&nbsp; 	  
      Aarush Gupta<sup>7*</sup>&nbsp;<br/>
	  <a href="https://wdjang.github.io/">Won-Dong Jang</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
	  Xueying Wang<sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://sites.google.com/site/iargandacarreras/"> Ignacio Arganda-Carreras<sup>2,3,8</sup>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://lichtmanlab.fas.harvard.edu/people/jeff-lichtman">Jeff W. Lichtman<sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
	  <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
	</div>
	<div class="affiliations">
	  <sup>1</sup>Harvard University&nbsp;&nbsp;&nbsp;&nbsp;  
	  <sup>2</sup>Donostia International Physics Center&nbsp;&nbsp;&nbsp;&nbsp;
      <sup>3</sup>University of the Basque Country<br/>
	  <sup>4</sup>Technical University of Munich&nbsp;&nbsp;&nbsp;&nbsp;
	  <sup>5</sup>Shanghai Jiao Tong University&nbsp;&nbsp;&nbsp;&nbsp;
	  <sup>6</sup>Northeastern University<br/>
	  <sup>7</sup>Indian Institute of Technology Roorkee&nbsp;&nbsp;&nbsp;&nbsp;
	  <sup>8</sup>Ikerbasque, Basque Foundation for Science
	</div>
	<div>* Works are done as interns at Harvard University</div>
      
      </div>
      <center>
      <font size=4>
MICCAI 2020 [<a href="../../paper/2020_miccai_mitoEM.pdf">Paper</a>] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Code [<a href="https://zudi-lin.github.io/pytorch_connectomics/build/html/tutorials/mitoem.html">Github</a>]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
Dataset [<a href="https://www.dropbox.com/sh/vfaavfmcmdfvwz1/AAAF7niWhVFDLrRn2ZsQobD_a?dl=0">Dropbox</a>]
      </font>
      </center>
<br/>    
<br/>    
<br/>    
      <center><img src="./src/mitoEM_teaser.png" border="0" width="80%"></center>

<div class="section abstract">
	<h2>Abstract</h2>
	<br>
	<p>	&nbsp;&nbsp;&nbsp;&nbsp;Electron microscopy (EM) allows the identification of intracellular organelles such as mitochondria, providing insights for clinical and scientific studies. However, public mitochondria segmentation datasets only contain hundreds of instances with simple shapes. It is unclear if existing methods achieving human-level accuracy on these small datasets are robust in practice. To this end, we introduce the <b> MitoEM</b> dataset, a 3D mitochondria instance segmentation dataset with two 30um cubic volumes from human and rat cortices respectively, <b>3,600x</b> larger than previous benchmarks. With around 40K instances, we find a great diversity of mitochondria in terms of shape and density. For evaluation, we tailor the implementation of the average precision (AP) metric for 3D data with a <b>45x</b> speedup. On MitoEM, we find existing instance segmentation methods often fail to correctly segment mitochondria with complex shapes or close contacts with other instances. Thus, our MitoEM dataset poses new challenges to the field. 
    </p>
      </div>

<br>
<div class="section materials">
<h2>Dataset Analysis</h2>
	<center><img src="./src/mitoEM_dataset.png" border="0" width="80%"></center>
    <p>We plot the length versus volume of mitochondria instances for both volumes, where the length of the mitochondria is approximated by the number of voxels in its 3D skeleton (Left).
    There is a strong linear correlation between the volume and length mitochondria in both volumes, which is the average thickness of the instance. While the MitoEM-H has more small instances, the MitoEM-R has more large instances with complex morphologies.
    We sample mitochondria of different length along the regression line and find instances share similar shapes to MOAS in both volumes (Right).
    </p>

<h2>Citation</h2>
<pre class="highlight">
@inproceedings{wei2020mitoem,
  title={MitoEM Dataset: Large-scale 3D Mitochondria Instance Segmentation from EM Images},
  author={D. Wei, Z. Lin, D. Barranco, N. Wendt, X. Liu, W. Yin, X. Huang, A. Gupta,<br/> W. Jang, X. Wang,  I. Arganda-Carreras, J. Lichtman, H. Pfister},
  booktitle={International Conference on Medical Image Computing and Computer Assisted Intervention},
  year={2020}
}
</pre>
<h2>Acknowledgement</h2>
<p>
This work has been partially supported by NSF award IIS-1835231 and NIH award 5U54CA225088-03.</p>
</div>

</div></div></body></html>
